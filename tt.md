진행했던 프로젝트 두 가지에 대하여 활용 기술, 본인의 역할, 진행 방식, 문제 해결 경험 등을 포함하여 구체적으로 설명해 주세요.
- 웹기반 빅데이터 분석 플랫폼 (레거시) 유지보수
  - 대용량 데이터 처리를 위한 파티셔닝 최적화 (단순 분석의 슬로우 쿼리를 대용량 분석 쿼리로 개선)



## 프로토콜의 흐름

1. 사용자는 내가 등록한 연결정보에 존재하는 데이터(시구, 시군구, 읍면동, 리, 본번, 부번, 지목부호, 등 법정동을 기반한 데이터)에 해당하는 폴리곤을 화면상에서 보고싶다
2. 데이터를 등록하게 되면 모델 정보(파일 혹은 db 를 이용한 스키마 정의)가 생성된다 
3. 등록된 데이터를 이용하여 만들어진 모델에 대한 DSL 명령어를 작성 후 백엔드에 dsl 쿼리를 전달한다 
4. 서버는 DSL 쿼리를 파싱해 파싱된 파라미터들로 pyspark udf 를 개발하여 사용자가 원하는 데이터를 프론트에 전달한다 (담당 : 개선 및 추가 개발) 
5. 프론트는 사용자가 원하는 폴리곤을 지도에 표현한다

## 당시 상황
100GB 이상의 행정동, 법정동에 대한 기준이 모호한 지도 데이터와 폴리곤 데이터를 함유하고 있는 .csv 파일을 단순 분할하여 각 spark node 마다 데이터를 보유하고 있다 
사용자가 등록한 데이터에 일치하는 폴리곤을 추출하여 사용자 데이터에 polygon 을 join 하여 다시 전달하고 있다

## 상황 파악
당시 해당 DSL 명령어는 무거운 폴리곤 데이터를 가지고 있기 때문에 조회를 하는게 당연히 느린 DSL 명령어라고 생각하여 단순 몇건에 대한 데이터에 polygon 데이터를 
join을 해주는 명령어로써 사용되고 있었다
그래서 나도 당시 처음에는 단순히 행정동, 법정동에 대한 기준이 모호한 지도 데이터를 최신의 데이터로 업데이트 하면서 기준만 재구축하려고 했었다
하지만 spark 를 사용하고 있는데 데이터 분석이 느린지에 대해서 이해를 할 수 없었다.

## 상황 분석
"100GB 이상의 행정동, 법정동에 대한 기준이 모호한 지도 데이터와 폴리곤 데이터를 함유하고 있는 .csv 파일을 단순 분할하여 각 spark node 마다 데이터를 보유"
내가 내렸던 상황에 대해 좀더 분석을 해보았다 특히 윗 문장을 분석했을때 가장 문제가 되는 2가지 부분을 발견했는데

첫번째로는 100GB 이상의 행정동, 법정동에 대한 기준이 모호한 지도 데이터와 폴리곤 데이터를 함유하고 있는 .csv 파일
두번째로는 .csv 파일을 단순 분할

이 두가지가 이 상황을 해결해 줄 수 있는 키 포인트라 생각했다

## 문제 해결

0. `100GB 이상의 행정동, 법정동에 대한 기준이 모호한 지도 데이터와 폴리곤 데이터를 함유하고 있는 .csv 파일` -> `100GB 이상의 법정동에 기반한 최신의 지도 데이터와 폴리곤 데이터를 함유하고 있는 .csv 파일`
일단 첫번째의 문제를 해결하기 전 나는 이 오래된 데이터를 최신의 데이터로 업데이트 하며 기준을 명확히 하려고 했었다
왜냐하면 오래된 데이터의 출처는 아무도 모르고(해당 데이터에 대한 문서가 없었다) 최초에 해당 프로젝트의 DSL 명령어를 개발했을때 생성해 놨던 데이터 였다
그래서 데이터 분석으로 추출된 데이터가 현재와는 일치하지 않은 데이터 였기도 했다
이 문제를 해결하기 위해서 데이터에 대한 정보도 따로 문서에 정리 해놓았는데 당시의 정보이다

---------------------------

### 0-1. 사전데이터의 과정

#### download

- 다운로드 주소: http://openapi.nsdi.go.kr/nsdi/#
    - 연속지적도형정보(SHP)파일 다운로드
- 좌표계: EPSG:5174
- 데이터 인코딩: cp949
- 데이터기준일자 : 2021-05-01

#### toWGS84 데이터

- 변경방법:         QGIS 3.18.0 활용
- 좌표계:           EPSG:4326
- 데이터 인코딩:    utf-8

#### 0-2. 연속지적도형 정보조회 서비스 컬럼 정의 (default 컬럼)

| 항목명(영문) | 항목명(국문)   | 항목크기 | 항목구분 | 샘플데이터                  | 항목설명                                                     |
| ------------ | -------------- | -------- | -------- | --------------------------- | ------------------------------------------------------------ |
| A0           | 원천도형ID     | 10       | 1        | 56498                       | 개방DB에서 정의한 연속지적도의 도형 ID                       |
| A1           | 고유번호       | 19       | 1        | 411731020010883000          | 각 필지를 서로 구별하기 위하여 필지마다 붙이는 고유한 번호   |
| A2           | 법정동 코드    | 10       | 1        | 4117310200                  | 토지가 소재한 행정구역코드(법정동코드) 10자리                |
| A3           | 법정동명       | 300      | 1        | 경기도 안양시 동안구 관양동 | 토지가 소재한 소재지의 행정구역 명칭(법정동명)               |
| A4           | 지번           | 8        | 1        | 1454-1<br/>883              | 필지에 부여하여 지적공부에 등록한 번호. 지번본번과 지번부번으로   구성 |
| A5           | 지번지목부호   | 200      | 1        | 1451-1대<br/>883장          | 연속지적도의 각 필지에 표시된 지번+지목부호                  |
| A6           | 데이터기준일자 | 36       | 1        | 2014-10-10                  | 데이터 작성 기준일자                                         |

- 항목구분 : 필수(1), 옵션(0), 1건 이상 복수건(1 ... n), 0건 또는 복수건 (0...n)


#### 0-3. 변경 컬럼명 정의

| 항목명(영문) | 변경 항목명(영문) | 항목명(국문) | 예시                        |
| ------------ | ----------------- | ------------ | --------------------------- |
| WKT          | WKT               | X            | polygon~~~~                 |
| A0           | SGG_OID           | 원천도형ID   | 56498                       |
| A1           | PNU               | 고유번호     | 411731020010883000          |
| A2           | BJD_CD            | 법정동 코드  | 4117310200                  |
| A3           | BJD_NM            | 법정동명     | 경기도 안양시 동안구 관양동 |
|              | SI_NM             | 시도         | 경기도                      |
|              | SGG_NM            | 시군구       | 안양시 동안구               |
|              | EMD_NM            | 읍면동       | 관양동                      |
|              | RI_NM             | 리           | 금남리                      |
| A4           | BONBUN            | 본번         | 1454 or 산1454              |
|              | BUBON             | 부번         | 12                          |
| A5           | JIMOK             | 지목부호     | 대                          |



#### 0-4. 서울 최종 데이터 예시


| WKT                                                          | SGG_OID | PNU                 | BJD_CD     | BJD_NM                   | SI_NM      | SGG_NM | EMD_NM | RI_NM | BONBUN | BUBON | JIMOK |
| ------------------------------------------------------------ | ------- | ------------------- | ---------- | ------------------------ | ---------- | ------ | ------ | ----- | ------ | ----- | ----- |
| MULTIPOLYGON (((126.968673524572 37.5904663101548...)))      | 206422  | 1111010100100009980 | 1111010100 | 서울특별시 종로구 청운동 | 서울특별시 | 종로구 | 청운동 |       | 1      |       | 대    |
| MULTIPOLYGON (((126.968631991748 37.5904445217881...)))      | 164661  | 1111010100100009980 | 1111010100 | 서울특별시 종로구 청운동 | 서울특별시 | 종로구 | 청운동 |       | 1      | 3     | 대    |
| MULTIPOLYGON (((126.961894185078 37.578484470874 .......)))  | 169625  | 1111011500200009980 | 1111011500 | 서울특별시 종로구 사직동 | 서울특별시 | 종로구 | 사직동 |       | 산1    | 25    | 도    |
| MULTIPOLYGON (((126.961607472317 37.5781525859572 .........))) | 169622  | 1111011500200009980 | 1111011500 | 서울특별시 종로구 사직동 | 서울특별시 | 종로구 | 사직동 |       | 산1    |       | 공    |



#### 0-5. 데이터 만드는 과정

- 다운로드 주소에서 shp 파일 시도 구분으로 전부 다운로드
- qgis에서 shp 파일 불러오기
- 불러온 파일 객체식별 => 정보 => 속성 원본 =>CP949
- 원하는 좌표계로 바꾸기(포맷 =  csv) = > export => wgs84로, 인코딩 utf8
- geometry를 AS_WKT
- 생성된 레이어의 좌표가 맞는지 확인하기 => 아래 좌표(경도, 위도)나옴
- 좌표로 구글, 네이버, 카카오 등 맵에서 직접 비교하면서 확인하기
- default 컬럼으로 구성 되어 있는 csv 파일 확인하기
- csv 파일의 컬럼을 원하는 구성에 맞춰서 파싱하여 새로 저장
- csv파일을 원하는 파일포멧에 맞게 저장

- 이를 시구, 시군구, 읍면동, 리, 본번, 부번, 지목부호, 등 법정동을 기반한 데이터에 전부 적용 한다


---------------------------

당시 무식하게 데이터를 만들었는데 그 이유는 `0-5. 데이터 만드는 과정`을 자동화 하게 되면 qgis 를 사용할 수 없었으며 노력 대비 효율이 현저히 떨어졌기 때문이다
실제도 스크립트를 만들어 자동화를 해봤으나 QGIS 를 사용하여 데이터를 추출하고 가공하는 과정에 비하면 몇배 이상의 시간이 들어가서 비효율적일수 밖에 없었다

이렇게 진행을 하게 되면 `연속지적도형 정보조회 서비스 컬럼 정의`에서 지원하는 데이터를 내가 원하는 형태의 데이터로 변환을 할 수 있었는데 `변경 컬럼명 정의` 가 바로 그 형태이다 
이렇게 가장 최초에 진행 하려 했던 행정동, 법정동에 대한 기준이 모호한 지도 데이터를 최신의 법정동에 기반한 지적도 데이터로 업데이트를 만족했다

하지만 이는 데이터를 업데이트한 과정이며 여전히 대용량 분석에는 적합하지 않았다


1. `100GB 이상의 행정동, 법정동에 대한 기준이 모호한 데이터를 함유하고 있는 .csv 파일` -> `100GB 이하의 법정동에 기반한 최신의 데이터를 함유하고 있는 .parquet 파일`
현재 이 개선사항을 진행하는데 있어서 제약사항이 존재했는데 파일시스템 기반으로 개선을 해야하는 것이었다
이유는 업체에 납품되어 있는 환경들이 전부 파일시스템 기반이며 db 기반으로 변경을 하게 되면 소규모로 진행했던 개선사항의 목적이 상실되었기 때문이다
그리고 파일시스템 기반으로도 충분히 성능을 향상 시킬수 있다고 봤기 때문이다

이제 개선사항의 최초 목적을 이루었으니 문제 해결을 위한 작업이 필요했다

그중 csv 파일을 대용량으로 사용하고 있던 것이 가장 눈에 들어왔다
이유는 csv 파일은 row 기반의 데이터이며 이를 활용해 사용자가 원하는 데이터를 추출하는 방식은 인덱스가 존재하지 않는다면 모든 데이터를 로드해야 원하는 레코드를 찾을 수 있었기 때문이다
spark 가 inmemory 방식으로 동작한다 하여도 많은 디스크 IO가 발생하고, 성능 저하가 되기 때문에 내가 원하는 방향에는 전혀 어울리지 않는 파일 포맷 이었다

이를 해결하기 위해 column 기반의 데이터 포맷을 찾았다
이유는 column 별로 데이터가 저장되어 있기 때문에, 데이터 분석시 필요한 column 만을 로드 하여 디스크 IO를 줄이고
모든 column 을 가져올 필요가 없고 DSL 쿼리에서 요구 되는 column 만 읽을 수 있기 때문에 속도가 row 기반 처리 방식에 비해서 높은 성능을 가질수 있기 때문이다

마침 내가 생각했던을 spark 는 이미 반영을 하고 있었다. 특히 .parquet 포맷형태를 지원하고 있었으며

이를 사용함으로써 원본 데이터의 압축률도 좋아지고 spark 를 사용함에 있어 능률도 향상시킬수 있었다.


---------------------------

### 1. 시도, 시군구, 읍면동, .... -> WKT 정보

#### 1-1. 시도 컬럼을 기준으로 파일 구성

```
.
├--- 서울
|   └---- part-00000-ae704512-c6db-4f85-81e1-c02458d94ec6-c000.snappy.parquet
|   └---- part-00001-ae704512-c6db-4f85-81e1-c02458d94ec6-c000.snappy.parquet
|   └---- part-00002-ae704512-c6db-4f85-81e1-c02458d94ec6-c000.snappy.parquet
├--- 세종
|   └---- part-00000-5644a4cb-a03b-4201-9f25-54151a9987ac-c000.snappy.parquet
.
.

```

#### 1-1-1. 결과 (13~15초)

- 매번 전체 데이터를 읽음으로 인해 오랜시간이 걸림
- 하지만 기존 아예 동작이 안된 대용량 분석 DSL 쿼리가 동작되기 시작함


2. `.csv 파일을 단순 분할` -> `.parquert 파일을 명확한 기준을 가지고 partitioning`
당시 csv 파일을 단순 분할하여 spark 의 분산처리를 이용하려 했던것 같았는데 이는 제대로 spark 를 활용하지 못한것이라 생각했다
물론 내부 데이터에 명확한 기준이 있어 그를 활용해 파일을 분할 했다면 이점을 살릴수 있었겠으나 이는 진행되지 않고 그저 데이터 덩어리로만 남겨져 있어 이를 개선하기로 생각했다
처음으로 데이터를 분할하기에 앞서서 명확한 기준인 시도, 시군구, 읍면동, 리 로 기준을 잡았다
이를 이용해 각 기준점을 컬럼으로 생각하면 기준에 대한 데이터만 불러와 필요없는 데이터의 로드는 줄일수 있지않을까 하고 생각했었으며
특히 spark 의 parquet partitioning 을 이용하여 parquet 파일을 사용하는데 있어 최대의 이점을 얻을수 있었다



#### 1-2. 시도, 시군구, 읍면동, 리 를 기준으로 파일구성

```
.
└--- 서울
|   ├---- 종로구
|   |     └---- 익선동
|   |          └-----NULL
|   |               └---- part-00000-ae704512-c6db-4f85-81e1-c02458d94ec6-c000.snappy.parquet
|   ├---- 강동구
|   |     └---- 익선동
|   |          └-----NULL
|   |               └---- part-00000-ae704512-c6db-4f85-81e1-c02458d94ec6-c000.snappy.parquet
|   ├---- 송파구
|   ├---- 서초구
|   ....
├--- 세종
....

```

#### 1-2-1. 결과 (3~4초)

- 시도, 시군구, 읍면동, 리를 기준으로 나눠 파일트리 구성
- 데이터값이 잘못됐을 경우 혹은 전체를 포함하고 싶은경우에는 다시 제대로 수정해줘야함
- 기존 시도 컬럼을 기준으로 파일 구성한 결과보다 2배 이상 시간 단축



#### 1-3. 시도, 시군구, 읍면동, 리 를 기준으로 parquet partitioning

```
.
└--- SI_NM=서울특별시
|   ├---- SGG=종로구
|   |     └---- 익선동
|   |          └-----NULL
|   |               └---- part-00000-ae704512-c6db-4f85-81e1-c02458d94ec6-c000.snappy.parquet
|   ├---- 강동구
|   |     └---- 익선동
|   |          └-----NULL
|   |               └---- part-00000-ae704512-c6db-4f85-81e1-c02458d94ec6-c000.snappy.parquet
|   ├---- 송파구
|   ├---- 서초구
|   ....
├--- sejong
....

```

#### 1-3-1. 결과 (1~2초)

- spark를 이용하여 parquet파일을 partitioning 함
- 데이터값이 잘못됐을 경우 혹은 전체를 포함하고 싶은경우 * 를 이용하여 그부분을 read할 수 있음
- 시도, 시군구, 읍면동, 리 를 기준으로 파일구성한 경우보다 2배 이상 시간 단축


#### 결론
- 활용 기술, 본인의 역할, 진행 방식, 문제 해결 경험
- 아예 동작하지 않던 대용량 분석 DSL 쿼리 -> 1~2 초 대의 DSL 쿼리 로 개선
- 이후 프론트 팀에서 Map 관련 명령어를 이용한 팀 구축


---
파일 기반 데이터 분석 플랫폼 개발
활용 언어 및 툴: Java(Spring, JPA, Maven, Flyway, Junit5), Python(FastAPI, SQLAlchemy, Pandas, TextRank, Mecab, unittest, flake8) 
Http, MariaDB, Jenkins, ngrinder, Docker, k8s, GitHub, Jira, Swagger

당시 화면 기획부터 설계, 개발 까지 하나의 프로젝트 내에서 2개의 서비스를 6개월에 걸쳐 담당하였다.

프로젝트의 주된 내용은 분산 코드 실행 및 관리 서비스 개발이다.

AMS(Java) - AES(Python) - Task(언어 무관)
서비스에는 Agent Manager Service(AMS) 와 Agent Executor Service(AES) 가 있으며
AMS 는 AES와 AES에서 생성된 Task 를 Monitoring 하며 관리한다
AES 는 AMS 를 통해 api 를 request 받으면 subProcess 를 생성하여 분석을 시작하는데 이때 subProcess 는 Task 라는 개념으로 사용된다
Task 는 사용자 혹은 개발자가 AES 에 등록한 프로그램을 실행한다

사용자는 AMS 를 통해 remote 서버에서 돌고있는 AES에 데이터 분석 프로그램을 등록할 수 있고 api 를 통해 등록된 코드로 분석을 실행할 수 있으며
결과를 저장해놓거나 바로 결과를 받을수 있다

AMS 는 k8s 의 pod 을 관리하는 서비스에 연동해 AES 의 스케일링이 가능하고 실행중인 AES 와 Task 를 모니터링 할 수 있다

이 프로젝트를 하면서 초기에 AMS, AES 각 서비스마다 pod 을 하나씩 띄워서 개발을 하는동안 전혀 문제가 발생하기 않았는데 pod 을 관리하는 서비스에 연동시 AES 의 pod 이
늘어남에 있어 하나의 file 에 여러개의 pod 이 동시에 붙으면서 문제가 발생했었다. 이를 해결하기 위해 Locking Mechanism 을 이용하였으며 이를 통해 여러개의 프로세스가 
동시에 작업을 하여도 문제가 발생하던것을 해결할 수 있었다






본인의 역할: 전체 시스템 기획부터 설계, 개발까지 담당, 이중 주요 서비스인 Agent Manager Service(AMS)와 Agent Executor Service(AES) 개발

진행 방식: 6개월 동안 두 개의 서비스를 개발, AMS는 AES와 AES에서 생성된 Task(서브 프로세스)를 모니터링하며 관리하고, AES는 AMS로부터 API를 통해 요청을 받아
Task(서브 프로세스)를 생성하여 데이터 분석 작업을 시작하는 구조를 개발. 또한, AMS를 k8s의 pod 관리 서비스에 연동하여 AES의 스케일링이 가능하도록 구현하였습니다

문제 해결 경험: 프로젝트 초기에는 AMS와 AES가 각각 하나의 pod에서 작동하면서 문제가 없었지만, pod 관리 서비스에 연동한 후 AES pod가 늘어나면서 하나의 파일에 여러 pod가 동시에 접근하는 문제가 발생했습니다
이를 해결하기 위해 Locking Mechanism을 도입하여, 여러 개의 프로세스가 동시에 작업을 수행하더라도 문제가 발생하지 않도록 개선했습니다


[프로젝트 이름]
파일 기반 데이터 분석 플랫폼 개발
[활용 기술]
Java(Spring, JPA, Maven, Flyway, Junit5), Python(FastAPI, SQLAlchemy, Pandas, TextRank, Mecab, unittest, flake8), 
Http, MariaDB, Jenkins, ngrinder, Docker, k8s, GitHub, Jira, Swagger
[본인의 역할]
기획부터 설계, 개발까지의 담당했습니다. 프로젝트는 총 6개월(22.07.01 ~ 22.12.31) 동안 진행되었으며, 이 기간 동안 2개의 서비스를 개발했습니다
[진행 방식]
프로젝트의 주된 내용은 분산 코드 실행 및 잡스케줄링 개발이었습니다. 이를 위해 Agent Manager Service(AMS)와 Agent Executor Service(AES)라는 두 개의 서비스를 개발했습니다
AMS는 Java로 개발되었으며, AES와 AES에서 생성된 Task(subprocess)를 모니터링하고 관리하는 잡스케줄러의 마스터 역할을 하였습니다
AES는 Python으로 개발되었으며, AMS를 통해 API 요청을 받으면 Task(subprocess)를 생성하여 분석을 하는 워커 역할을 하였습니다
사용자는 AMS를 통해 원격 서버에서 동작 중인 AES에 데이터 분석 프로그램을 등록할 수 있었고, API를 통해 등록된 프로그램으로 분석을 실행할 수 있었습니다. 그리고 그 결과를 저장하거나 바로 받을 수 있었습니다.
AMS는 k8s의 pod를 관리하는 서비스와 연동되어 AES의 스케일링이 가능하도록 하였고, 실행 중인 AES와 Task(subprocess)를 모니터링 할 수 있었습니다.
[문제 해결 경험]
프로젝트를 진행하면서 가장 기억에 남았던 문제는 동시성 문제였습니다. 초기에는 AMS와 AES, 각각의 서비스마다 pod을 하나씩 구동하면서 개발을 진행하였습니다. 이 때에는 동시성 문제가 발생하지 않았습니다.
그러나 프로젝트가 진행되면서 pod 관리를 자동화하는 단계로 넘어갔을 때 문제가 발생하였습니다. Kubernetes의 자동 스케일링 기능에 의해 AES의 pod 개수가 증가함에 따라, 여러 개의 pod이 동일한 파일에 동시에 액세스하는 상황이 발생하였습니다.
이러한 동시성 문제를 해결하기 위해 락(Locking Mechanism)을 도입하였습니다. 락을 이용하면 여러 개의 프로세스가 동시에 같은 자원에 접근하려고 할 때, 한 번에 하나의 프로세스만 접근할 수 있도록 제어할 수 있습니다. 
이 방법을 통해 동시성 문제를 해결했었습니다
이 경험을 통해 분산 시스템에서 동시성 문제는 불가피하며, 이를 처리하는 방법을 알아야 한다는 것을 깨달았습니다. 특히, Locking Mechanism을 적용하면서 동시성 제어의 중요성을 체감했습니다.


---


[프로젝트 이름]
sql+dsl 기반 데이터 분석 플랫폼 개발
[활용기술]
Python(FastAPI, SQLAlchemy, alembic, Yacc, Lex, Pandas, Polars, Mecab, doctest, unittest, flake8), Http, Https, Grpc, 
MariaDB, PostgreSQL, Redis, Tibero, Oracle, Minio, HDFS, 자체DB, Jenkins(Declarative pipeline, Scripted pipeline), 
ArgoCD, Sonarqube, ngrinder, Sentry, Docker, k8s, GitHub, GitLab, Jira, Swagger, Slack
[본인의 역할]
기획부터 설계, 개발까지의 담당했습니다. 프로젝트는 총 6개월 간의 개발 이후 현재까지 개선 및 유지보수 중입니다 (21.11.01 ~ 현재)
[진행 방식]
프로젝트의 주된 내용은 SQL+DSL 기반의 데이터 분석 서비스 개발이었습니다. 이전에는 Python과 Spark를 기반으로 한 DSL 기반 데이터 분석 플랫폼을 유지보수하고 있었으나,
중앙집중 처리 방식 때문에 많은 쿼리가 동시에 들어올 때 처리 속도가 느려지는 문제가 있었습니다. 그리고 서비스의 타겟이 빅데이터였지만, 실제로는 그에 맞지 않는 작은 규모의 데이터를 주로 다루고 있었으며
사용자들은 이를 회피하기 위해 db에 직접 연동하는 서비스를 주로 사용하였으며 sql 을 사용하고 있었습니다.
이를 보완하기 위해, 기존의 프로젝트를 하위호환 가능한 SQL+DSL 형태의 구조로 변경하기로 결정했습니다. 성능 향상을 위해 pandas, polars, dask, modin의 성능을 비교 분석하였고,
이 중 polars가 가장 성능이 좋았습니다. 또한 개발 친화적이기 위해 polars+pandas 형태의 데이터 분석 플랫폼 구조를 채택하였습니다.

[문제 해결 경험]
프로젝트를 진행하면서 동시에 여러 SQL+DSL 쿼리가 서비스에 도착하면 성능 저하가 발생하는 문제를 발견하였습니다. 
이를 ngrinder를 이용하여 재현하였고, Python의 GIL 때문에 성능이 저하되는 것으로 판단하였습니다.
이 문제를 해결하기 위해, 원래 하나의 프로세스로 운영되던 서비스를 5개의 다른 프로세스로 분리하여 성능 향상을 이루었습니다.
1. 메인 서버 (Main Server): API 요청을 처리하고 전반적인 서비스 관리를 담당합니다
2. PreFork 서버 (PreFork Server): subprocess를 미리 fork 하여 db와 connection 을 미리 맺어놓고 SQL 쿼리를 처리합니다
3. Fork 서버 (Fork Server): SQL+DSL 쿼리가 들어올 때마다 subprocess를 fork하며, 쿼리 처리 작업의 부하를 줄였습니다
4. 모니터링 서버 (Monitoring Server): 각 subprocess의 상태를 모니터링하며, 특히 zombie process에 대한 관리를 철저히 하였습니다
5. 로그 서버 (Log Server): 각 프로세스에서 발생하는 로그를 관리하고 분석합니다
이러한 변경을 통해, 각 프로세스는 자신의 역할에 집중하고, 병목 현상을 최소화하여 성능을 향상을 하였습니다
추가로, ngrinder를 이용하여 성능 테스트를 수행하고, 이를 기반으로 서비스의 성능 개선을 지속적으로 모니터링하였습니다. 이 결과, 원래 2초가 걸리던 쿼리 처리 시간을 1초 이하로 줄여, 성능을 2배 이상 향상시킬 수 있었습니다.
이 경험을 통해, 성능 문제에 직면했을 때 시스템을 세분화하고, 특정 부분에 집중하여 문제를 해결하는 방법에 대해 배울 수 있었습니다. 또한 성능 개선에 있어 지속적인 모니터링과 테스트의 중요성을 다시 한 번 인지하게 되었습니다.


[지원동기] - 회사명 써있으니까 수정할것
현재 다니고 있는 회사는 첫 회사로 하고 있는 일은 데이터분석 플랫폼 개발입니다
100명 가량의 사람들이 내가 만든 프로그램을 사용하고 있는것에는 만족감을 느끼고 있었습니다.
하지만 과연 좀 더 많은 사람들이 이용하는 플랫폼에도 내가 도움이 되지않을까 하는 생각도 매번 가지고 있었습니다
그렇게 생각만을 하고 있었던 저에게 가장 큰 동기부여가 되는 일이 있었습니다
aws 에서 하루동안 주최하는 워크샵에 참여하고 난 후 각 분야에서 프로라고 하는 사람들을 마주보게 되었을때 왜 나는 이 분야에서 만족감 만을 느끼고 프로가 되지 않으려고 하는가에 대해서 생각을 가지게 되었고 내가 현재 너무 안주하고 있는 삶을 사는게 아닌가하는 마음이 들었습니다
그래서 예전부터 스스로 프로의 영역이라는 [회사명]에 지원하는것이 나 스스로에게도 발전의 의미를 주는 시간이 되지않을까 하는 의미로 지원하게 되었습니다