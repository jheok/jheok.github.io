진행했던 프로젝트 두 가지에 대하여 활용 기술, 본인의 역할, 진행 방식, 문제 해결 경험 등을 포함하여 구체적으로 설명해 주세요.
- 웹기반 빅데이터 분석 플랫폼 (레거시) 유지보수
  - 대용량 데이터 처리를 위한 파티셔닝 최적화 (단순 분석의 슬로우 쿼리를 대용량 분석 쿼리로 개선)



## 프로토콜의 흐름

1. 사용자는 내가 등록한 연결정보에 존재하는 데이터(시구, 시군구, 읍면동, 리, 본번, 부번, 지목부호, 등 법정동을 기반한 데이터)에 해당하는 폴리곤을 화면상에서 보고싶다
2. 데이터를 등록하게 되면 모델 정보(파일 혹은 db 를 이용한 스키마 정의)가 생성된다 
3. 등록된 데이터를 이용하여 만들어진 모델에 대한 DSL 명령어를 작성 후 백엔드에 dsl 쿼리를 전달한다 
4. 서버는 DSL 쿼리를 파싱해 파싱된 파라미터들로 pyspark udf 를 개발하여 사용자가 원하는 데이터를 프론트에 전달한다 (담당 : 개선 및 추가 개발) 
5. 프론트는 사용자가 원하는 폴리곤을 지도에 표현한다

## 당시 상황
100GB 이상의 행정동, 법정동에 대한 기준이 모호한 지도 데이터와 폴리곤 데이터를 함유하고 있는 .csv 파일을 단순 분할하여 각 spark node 마다 데이터를 보유하고 있다 
사용자가 등록한 데이터에 일치하는 폴리곤을 추출하여 사용자 데이터에 polygon 을 join 하여 다시 전달하고 있다

## 상황 파악
당시 해당 DSL 명령어는 무거운 폴리곤 데이터를 가지고 있기 때문에 조회를 하는게 당연히 느린 DSL 명령어라고 생각하여 단순 몇건에 대한 데이터에 polygon 데이터를 
join을 해주는 명령어로써 사용되고 있었다
그래서 나도 당시 처음에는 단순히 행정동, 법정동에 대한 기준이 모호한 지도 데이터를 최신의 데이터로 업데이트 하면서 기준만 재구축하려고 했었다
하지만 spark 를 사용하고 있는데 데이터 분석이 느린지에 대해서 이해를 할 수 없었다.

## 상황 분석
"100GB 이상의 행정동, 법정동에 대한 기준이 모호한 지도 데이터와 폴리곤 데이터를 함유하고 있는 .csv 파일을 단순 분할하여 각 spark node 마다 데이터를 보유"
내가 내렸던 상황에 대해 좀더 분석을 해보았다 특히 윗 문장을 분석했을때 가장 문제가 되는 2가지 부분을 발견했는데

첫번째로는 100GB 이상의 행정동, 법정동에 대한 기준이 모호한 지도 데이터와 폴리곤 데이터를 함유하고 있는 .csv 파일
두번째로는 .csv 파일을 단순 분할

이 두가지가 이 상황을 해결해 줄 수 있는 키 포인트라 생각했다

## 문제 해결

0. `100GB 이상의 행정동, 법정동에 대한 기준이 모호한 지도 데이터와 폴리곤 데이터를 함유하고 있는 .csv 파일` -> `100GB 이상의 법정동에 기반한 최신의 지도 데이터와 폴리곤 데이터를 함유하고 있는 .csv 파일`
일단 첫번째의 문제를 해결하기 전 나는 이 오래된 데이터를 최신의 데이터로 업데이트 하며 기준을 명확히 하려고 했었다
왜냐하면 오래된 데이터의 출처는 아무도 모르고(해당 데이터에 대한 문서가 없었다) 최초에 해당 프로젝트의 DSL 명령어를 개발했을때 생성해 놨던 데이터 였다
그래서 데이터 분석으로 추출된 데이터가 현재와는 일치하지 않은 데이터 였기도 했다
이 문제를 해결하기 위해서 데이터에 대한 정보도 따로 문서에 정리 해놓았는데 당시의 정보이다

---------------------------

### 0-1. 사전데이터의 과정

#### download

- 다운로드 주소: http://openapi.nsdi.go.kr/nsdi/#
    - 연속지적도형정보(SHP)파일 다운로드
- 좌표계: EPSG:5174
- 데이터 인코딩: cp949
- 데이터기준일자 : 2021-05-01

#### toWGS84 데이터

- 변경방법:         QGIS 3.18.0 활용
- 좌표계:           EPSG:4326
- 데이터 인코딩:    utf-8

#### 0-2. 연속지적도형 정보조회 서비스 컬럼 정의 (default 컬럼)

| 항목명(영문) | 항목명(국문)   | 항목크기 | 항목구분 | 샘플데이터                  | 항목설명                                                     |
| ------------ | -------------- | -------- | -------- | --------------------------- | ------------------------------------------------------------ |
| A0           | 원천도형ID     | 10       | 1        | 56498                       | 개방DB에서 정의한 연속지적도의 도형 ID                       |
| A1           | 고유번호       | 19       | 1        | 411731020010883000          | 각 필지를 서로 구별하기 위하여 필지마다 붙이는 고유한 번호   |
| A2           | 법정동 코드    | 10       | 1        | 4117310200                  | 토지가 소재한 행정구역코드(법정동코드) 10자리                |
| A3           | 법정동명       | 300      | 1        | 경기도 안양시 동안구 관양동 | 토지가 소재한 소재지의 행정구역 명칭(법정동명)               |
| A4           | 지번           | 8        | 1        | 1454-1<br/>883              | 필지에 부여하여 지적공부에 등록한 번호. 지번본번과 지번부번으로   구성 |
| A5           | 지번지목부호   | 200      | 1        | 1451-1대<br/>883장          | 연속지적도의 각 필지에 표시된 지번+지목부호                  |
| A6           | 데이터기준일자 | 36       | 1        | 2014-10-10                  | 데이터 작성 기준일자                                         |

- 항목구분 : 필수(1), 옵션(0), 1건 이상 복수건(1 ... n), 0건 또는 복수건 (0...n)


#### 0-3. 변경 컬럼명 정의

| 항목명(영문) | 변경 항목명(영문) | 항목명(국문) | 예시                        |
| ------------ | ----------------- | ------------ | --------------------------- |
| WKT          | WKT               | X            | polygon~~~~                 |
| A0           | SGG_OID           | 원천도형ID   | 56498                       |
| A1           | PNU               | 고유번호     | 411731020010883000          |
| A2           | BJD_CD            | 법정동 코드  | 4117310200                  |
| A3           | BJD_NM            | 법정동명     | 경기도 안양시 동안구 관양동 |
|              | SI_NM             | 시도         | 경기도                      |
|              | SGG_NM            | 시군구       | 안양시 동안구               |
|              | EMD_NM            | 읍면동       | 관양동                      |
|              | RI_NM             | 리           | 금남리                      |
| A4           | BONBUN            | 본번         | 1454 or 산1454              |
|              | BUBON             | 부번         | 12                          |
| A5           | JIMOK             | 지목부호     | 대                          |



#### 0-4. 서울 최종 데이터 예시


| WKT                                                          | SGG_OID | PNU                 | BJD_CD     | BJD_NM                   | SI_NM      | SGG_NM | EMD_NM | RI_NM | BONBUN | BUBON | JIMOK |
| ------------------------------------------------------------ | ------- | ------------------- | ---------- | ------------------------ | ---------- | ------ | ------ | ----- | ------ | ----- | ----- |
| MULTIPOLYGON (((126.968673524572 37.5904663101548...)))      | 206422  | 1111010100100009980 | 1111010100 | 서울특별시 종로구 청운동 | 서울특별시 | 종로구 | 청운동 |       | 1      |       | 대    |
| MULTIPOLYGON (((126.968631991748 37.5904445217881...)))      | 164661  | 1111010100100009980 | 1111010100 | 서울특별시 종로구 청운동 | 서울특별시 | 종로구 | 청운동 |       | 1      | 3     | 대    |
| MULTIPOLYGON (((126.961894185078 37.578484470874 .......)))  | 169625  | 1111011500200009980 | 1111011500 | 서울특별시 종로구 사직동 | 서울특별시 | 종로구 | 사직동 |       | 산1    | 25    | 도    |
| MULTIPOLYGON (((126.961607472317 37.5781525859572 .........))) | 169622  | 1111011500200009980 | 1111011500 | 서울특별시 종로구 사직동 | 서울특별시 | 종로구 | 사직동 |       | 산1    |       | 공    |



#### 0-5. 데이터 만드는 과정

- 다운로드 주소에서 shp 파일 시도 구분으로 전부 다운로드
- qgis에서 shp 파일 불러오기
- 불러온 파일 객체식별 => 정보 => 속성 원본 =>CP949
- 원하는 좌표계로 바꾸기(포맷 =  csv) = > export => wgs84로, 인코딩 utf8
- geometry를 AS_WKT
- 생성된 레이어의 좌표가 맞는지 확인하기 => 아래 좌표(경도, 위도)나옴
- 좌표로 구글, 네이버, 카카오 등 맵에서 직접 비교하면서 확인하기
- default 컬럼으로 구성 되어 있는 csv 파일 확인하기
- csv 파일의 컬럼을 원하는 구성에 맞춰서 파싱하여 새로 저장
- csv파일을 원하는 파일포멧에 맞게 저장

- 이를 시구, 시군구, 읍면동, 리, 본번, 부번, 지목부호, 등 법정동을 기반한 데이터에 전부 적용 한다


---------------------------

당시 무식하게 데이터를 만들었는데 그 이유는 `0-5. 데이터 만드는 과정`을 자동화 하게 되면 qgis 를 사용할 수 없었으며 노력 대비 효율이 현저히 떨어졌기 때문이다
실제도 스크립트를 만들어 자동화를 해봤으나 QGIS 를 사용하여 데이터를 추출하고 가공하는 과정에 비하면 몇배 이상의 시간이 들어가서 비효율적일수 밖에 없었다

이렇게 진행을 하게 되면 `연속지적도형 정보조회 서비스 컬럼 정의`에서 지원하는 데이터를 내가 원하는 형태의 데이터로 변환을 할 수 있었는데 `변경 컬럼명 정의` 가 바로 그 형태이다 
이렇게 가장 최초에 진행 하려 했던 행정동, 법정동에 대한 기준이 모호한 지도 데이터를 최신의 법정동에 기반한 지적도 데이터로 업데이트를 만족했다

하지만 이는 데이터를 업데이트한 과정이며 여전히 대용량 분석에는 적합하지 않았다


1. `100GB 이상의 행정동, 법정동에 대한 기준이 모호한 데이터를 함유하고 있는 .csv 파일` -> `100GB 이하의 법정동에 기반한 최신의 데이터를 함유하고 있는 .parquet 파일`
현재 이 개선사항을 진행하는데 있어서 제약사항이 존재했는데 파일시스템 기반으로 개선을 해야하는 것이었다
이유는 업체에 납품되어 있는 환경들이 전부 파일시스템 기반이며 db 기반으로 변경을 하게 되면 소규모로 진행했던 개선사항의 목적이 상실되었기 때문이다
그리고 파일시스템 기반으로도 충분히 성능을 향상 시킬수 있다고 봤기 때문이다

이제 개선사항의 최초 목적을 이루었으니 문제 해결을 위한 작업이 필요했다

그중 csv 파일을 대용량으로 사용하고 있던 것이 가장 눈에 들어왔다
이유는 csv 파일은 row 기반의 데이터이며 이를 활용해 사용자가 원하는 데이터를 추출하는 방식은 인덱스가 존재하지 않는다면 모든 데이터를 로드해야 원하는 레코드를 찾을 수 있었기 때문이다
spark 가 inmemory 방식으로 동작한다 하여도 많은 디스크 IO가 발생하고, 성능 저하가 되기 때문에 내가 원하는 방향에는 전혀 어울리지 않는 파일 포맷 이었다

이를 해결하기 위해 column 기반의 데이터 포맷을 찾았다
이유는 column 별로 데이터가 저장되어 있기 때문에, 데이터 분석시 필요한 column 만을 로드 하여 디스크 IO를 줄이고
모든 column 을 가져올 필요가 없고 DSL 쿼리에서 요구 되는 column 만 읽을 수 있기 때문에 속도가 row 기반 처리 방식에 비해서 높은 성능을 가질수 있기 때문이다

마침 내가 생각했던을 spark 는 이미 반영을 하고 있었다. 특히 .parquet 포맷형태를 지원하고 있었으며

이를 사용함으로써 원본 데이터의 압축률도 좋아지고 spark 를 사용함에 있어 능률도 향상시킬수 있었다.


---------------------------

### 1. 시도, 시군구, 읍면동, .... -> WKT 정보

#### 1-1. 시도 컬럼을 기준으로 파일 구성

```
.
├--- 서울
|   └---- part-00000-ae704512-c6db-4f85-81e1-c02458d94ec6-c000.snappy.parquet
|   └---- part-00001-ae704512-c6db-4f85-81e1-c02458d94ec6-c000.snappy.parquet
|   └---- part-00002-ae704512-c6db-4f85-81e1-c02458d94ec6-c000.snappy.parquet
├--- 세종
|   └---- part-00000-5644a4cb-a03b-4201-9f25-54151a9987ac-c000.snappy.parquet
.
.

```

#### 1-1-1. 결과 (13~15초)

- 매번 전체 데이터를 읽음으로 인해 오랜시간이 걸림
- 하지만 기존 아예 동작이 안된 대용량 분석 DSL 쿼리가 동작되기 시작함


2. `.csv 파일을 단순 분할` -> `.parquert 파일을 명확한 기준을 가지고 partitioning`
당시 csv 파일을 단순 분할하여 spark 의 분산처리를 이용하려 했던것 같았는데 이는 제대로 spark 를 활용하지 못한것이라 생각했다
물론 내부 데이터에 명확한 기준이 있어 그를 활용해 파일을 분할 했다면 이점을 살릴수 있었겠으나 이는 진행되지 않고 그저 데이터 덩어리로만 남겨져 있어 이를 개선하기로 생각했다
처음으로 데이터를 분할하기에 앞서서 명확한 기준인 시도, 시군구, 읍면동, 리 로 기준을 잡았다
이를 이용해 각 기준점을 컬럼으로 생각하면 기준에 대한 데이터만 불러와 필요없는 데이터의 로드는 줄일수 있지않을까 하고 생각했었으며
특히 spark 의 parquet partitioning 을 이용하여 parquet 파일을 사용하는데 있어 최대의 이점을 얻을수 있었다



#### 1-2. 시도, 시군구, 읍면동, 리 를 기준으로 파일구성

```
.
└--- 서울
|   ├---- 종로구
|   |     └---- 익선동
|   |          └-----NULL
|   |               └---- part-00000-ae704512-c6db-4f85-81e1-c02458d94ec6-c000.snappy.parquet
|   ├---- 강동구
|   |     └---- 익선동
|   |          └-----NULL
|   |               └---- part-00000-ae704512-c6db-4f85-81e1-c02458d94ec6-c000.snappy.parquet
|   ├---- 송파구
|   ├---- 서초구
|   ....
├--- 세종
....

```

#### 1-2-1. 결과 (3~4초)

- 시도, 시군구, 읍면동, 리를 기준으로 나눠 파일트리 구성
- 데이터값이 잘못됐을 경우 혹은 전체를 포함하고 싶은경우에는 다시 제대로 수정해줘야함
- 기존 시도 컬럼을 기준으로 파일 구성한 결과보다 2배 이상 시간 단축



#### 1-3. 시도, 시군구, 읍면동, 리 를 기준으로 parquet partitioning

```
.
└--- SI_NM=서울특별시
|   ├---- SGG=종로구
|   |     └---- 익선동
|   |          └-----NULL
|   |               └---- part-00000-ae704512-c6db-4f85-81e1-c02458d94ec6-c000.snappy.parquet
|   ├---- 강동구
|   |     └---- 익선동
|   |          └-----NULL
|   |               └---- part-00000-ae704512-c6db-4f85-81e1-c02458d94ec6-c000.snappy.parquet
|   ├---- 송파구
|   ├---- 서초구
|   ....
├--- sejong
....

```

#### 1-3-1. 결과 (1~2초)

- spark를 이용하여 parquet파일을 partitioning 함
- 데이터값이 잘못됐을 경우 혹은 전체를 포함하고 싶은경우 * 를 이용하여 그부분을 read할 수 있음
- 시도, 시군구, 읍면동, 리 를 기준으로 파일구성한 경우보다 2배 이상 시간 단축


#### 결론
- 활용 기술, 본인의 역할, 진행 방식, 문제 해결 경험
- 아예 동작하지 않던 대용량 분석 DSL 쿼리 -> 1~2 초 대의 DSL 쿼리 로 개선
- 이후 프론트 팀에서 Map 관련 명령어를 이용한 팀 구축


---
파일 기반 데이터 분석 플랫폼 개발
활용 언어 및 툴: Java(Spring, JPA, Maven, Flyway, Junit5), Python(FastAPI, SQLAlchemy, Pandas, TextRank, Mecab, unittest, flake8) 
Http, MariaDB, Jenkins, ngrinder, Docker, k8s, GitHub, Jira, Swagger

당시 화면 기획부터 설계, 개발 까지 하나의 프로젝트 내에서 2개의 서비스를 6개월에 걸쳐 담당하였다.

프로젝트의 주된 내용은 분산 코드 실행 및 관리 서비스 개발이다.

AMS(Java) - AES(Python) - Task(언어 무관)
서비스에는 Agent Manager Service(AMS) 와 Agent Executor Service(AES) 가 있으며
AMS 는 AES와 AES에서 생성된 Task 를 Monitoring 하며 관리한다
AES 는 AMS 를 통해 api 를 request 받으면 subProcess 를 생성하여 분석을 시작하는데 이때 subProcess 는 Task 라는 개념으로 사용된다
Task 는 사용자 혹은 개발자가 AES 에 등록한 프로그램을 실행한다

사용자는 AMS 를 통해 remote 서버에서 돌고있는 AES에 데이터 분석 프로그램을 등록할 수 있고 api 를 통해 등록된 코드로 분석을 실행할 수 있으며
결과를 저장해놓거나 바로 결과를 받을수 있다

AMS 는 k8s 의 pod 을 관리하는 서비스에 연동해 AES 의 스케일링이 가능하고 실행중인 AES 와 Task 를 모니터링 할 수 있다

이 프로젝트를 하면서 초기에 AMS, AES 각 서비스마다 pod 을 하나씩 띄워서 개발을 하는동안 전혀 문제가 발생하기 않았는데 pod 을 관리하는 서비스에 연동시 AES 의 pod 이
늘어남에 있어 하나의 file 에 여러개의 pod 이 동시에 붙으면서 문제가 발생했었다. 이를 해결하기 위해 Locking Mechanism 을 이용하였으며 이를 통해 여러개의 프로세스가 
동시에 작업을 하여도 문제가 발생하던것을 해결할 수 있었다






본인의 역할: 전체 시스템 기획부터 설계, 개발까지 담당, 이중 주요 서비스인 Agent Manager Service(AMS)와 Agent Executor Service(AES) 개발

진행 방식: 6개월 동안 두 개의 서비스를 개발, AMS는 AES와 AES에서 생성된 Task(서브 프로세스)를 모니터링하며 관리하고, AES는 AMS로부터 API를 통해 요청을 받아
Task(서브 프로세스)를 생성하여 데이터 분석 작업을 시작하는 구조를 개발. 또한, AMS를 k8s의 pod 관리 서비스에 연동하여 AES의 스케일링이 가능하도록 구현하였습니다

문제 해결 경험: 프로젝트 초기에는 AMS와 AES가 각각 하나의 pod에서 작동하면서 문제가 없었지만, pod 관리 서비스에 연동한 후 AES pod가 늘어나면서 하나의 파일에 여러 pod가 동시에 접근하는 문제가 발생했습니다
이를 해결하기 위해 Locking Mechanism을 도입하여, 여러 개의 프로세스가 동시에 작업을 수행하더라도 문제가 발생하지 않도록 개선했습니다


[프로젝트 이름]
파일 기반 데이터 분석 플랫폼 개발
[활용 기술]
Java(Spring, JPA, Maven, Flyway, Junit5), Python(FastAPI, SQLAlchemy, Pandas, TextRank, Mecab, unittest, flake8), 
Http, MariaDB, Jenkins, ngrinder, Docker, k8s, GitHub, Jira, Swagger
[본인의 역할]
기획부터 설계, 개발까지의 담당했습니다. 프로젝트는 총 6개월(22.07.01 ~ 22.12.31) 동안 진행되었으며, 이 기간 동안 2개의 서비스를 개발했습니다
[진행 방식]
프로젝트의 주된 내용은 분산 코드 실행 및 잡스케줄링 개발이었습니다. 이를 위해 Agent Manager Service(AMS)와 Agent Executor Service(AES)라는 두 개의 서비스를 개발했습니다
AMS는 Java로 개발되었으며, AES와 AES에서 생성된 Task(subprocess)를 모니터링하고 관리하는 잡스케줄러의 마스터 역할을 하였습니다
AES는 Python으로 개발되었으며, AMS를 통해 API 요청을 받으면 Task(subprocess)를 생성하여 분석을 하는 워커 역할을 하였습니다
사용자는 AMS를 통해 원격 서버에서 동작 중인 AES에 데이터 분석 프로그램을 등록할 수 있었고, API를 통해 등록된 프로그램으로 분석을 실행할 수 있었습니다. 그리고 그 결과를 저장하거나 바로 받을 수 있었습니다.
AMS는 k8s의 pod를 관리하는 서비스와 연동되어 AES의 스케일링이 가능하도록 하였고, 실행 중인 AES와 Task(subprocess)를 모니터링 할 수 있었습니다.
[문제 해결 경험]
프로젝트를 진행하면서 가장 기억에 남았던 문제는 동시성 문제였습니다. 초기에는 AMS와 AES, 각각의 서비스마다 pod을 하나씩 구동하면서 개발을 진행하였습니다. 이 때에는 동시성 문제가 발생하지 않았습니다.
그러나 프로젝트가 진행되면서 pod 관리를 자동화하는 단계로 넘어갔을 때 문제가 발생하였습니다. Kubernetes의 자동 스케일링 기능에 의해 AES의 pod 개수가 증가함에 따라, 여러 개의 pod이 동일한 파일에 동시에 액세스하는 상황이 발생하였습니다.
이러한 동시성 문제를 해결하기 위해 락(Locking Mechanism)을 도입하였습니다. 락을 이용하면 여러 개의 프로세스가 동시에 같은 자원에 접근하려고 할 때, 한 번에 하나의 프로세스만 접근할 수 있도록 제어할 수 있습니다. 
이 방법을 통해 동시성 문제를 해결했었습니다
이 경험을 통해 분산 시스템에서 동시성 문제는 불가피하며, 이를 처리하는 방법을 알아야 한다는 것을 깨달았습니다. 특히, Locking Mechanism을 적용하면서 동시성 제어의 중요성을 체감했습니다.


---


[프로젝트 이름]
sql+dsl 기반 데이터 분석 플랫폼 개발
[활용기술]
Python(FastAPI, SQLAlchemy, alembic, Yacc, Lex, Pandas, Polars, Mecab, doctest, unittest, flake8), Http, Https, Grpc, 
MariaDB, PostgreSQL, Redis, Tibero, Oracle, Minio, HDFS, 자체DB, Jenkins(Declarative pipeline, Scripted pipeline), 
ArgoCD, Sonarqube, ngrinder, Sentry, Docker, k8s, GitHub, GitLab, Jira, Swagger, Slack
[본인의 역할]
기획부터 설계, 개발까지의 담당했습니다. 프로젝트는 총 6개월 간의 개발 이후 현재까지 개선 및 유지보수 중입니다 (21.11.01 ~ 현재)
[진행 방식]
프로젝트의 주된 내용은 SQL+DSL 기반의 데이터 분석 서비스 개발이었습니다. 이전에는 Python과 Spark를 기반으로 한 DSL 기반 데이터 분석 플랫폼을 유지보수하고 있었으나,
중앙집중 처리 방식 때문에 많은 쿼리가 동시에 들어올 때 처리 속도가 느려지는 문제가 있었습니다. 그리고 서비스의 타겟이 빅데이터였지만, 실제로는 그에 맞지 않는 작은 규모의 데이터를 주로 다루고 있었으며
사용자들은 이를 회피하기 위해 db에 직접 연동하는 서비스를 주로 사용하였으며 sql 을 사용하고 있었습니다.
이를 보완하기 위해, 기존의 프로젝트를 하위호환 가능한 SQL+DSL 형태의 구조로 변경하기로 결정했습니다. 성능 향상을 위해 pandas, polars, dask, modin의 성능을 비교 분석하였고,
이 중 polars가 가장 성능이 좋았습니다. 또한 개발 친화적이기 위해 polars+pandas 형태의 데이터 분석 플랫폼 구조를 채택하였습니다.

[문제 해결 경험]
프로젝트를 진행하면서 동시에 여러 SQL+DSL 쿼리가 서비스에 도착하면 성능 저하가 발생하는 문제를 발견하였습니다. 
이를 ngrinder를 이용하여 재현하였고, Python의 GIL 때문에 성능이 저하되는 것으로 판단하였습니다.
이 문제를 해결하기 위해, 원래 하나의 프로세스로 운영되던 서비스를 5개의 다른 프로세스로 분리하여 성능 향상을 이루었습니다.
1. 메인 서버 (Main Server): API 요청을 처리하고 전반적인 서비스 관리를 담당합니다
2. PreFork 서버 (PreFork Server): subprocess를 미리 fork 하여 db와 connection 을 미리 맺어놓고 SQL 쿼리를 처리합니다
3. Fork 서버 (Fork Server): SQL+DSL 쿼리가 들어올 때마다 subprocess를 fork하며, 쿼리 처리 작업의 부하를 줄였습니다
4. 모니터링 서버 (Monitoring Server): 각 subprocess의 상태를 모니터링하며, 특히 zombie process에 대한 관리를 철저히 하였습니다
5. 로그 서버 (Log Server): 각 프로세스에서 발생하는 로그를 관리하고 분석합니다
이러한 변경을 통해, 각 프로세스는 자신의 역할에 집중하고, 병목 현상을 최소화하여 성능을 향상을 하였습니다
추가로, ngrinder를 이용하여 성능 테스트를 수행하고, 이를 기반으로 서비스의 성능 개선을 지속적으로 모니터링하였습니다. 이 결과, 원래 2초가 걸리던 쿼리 처리 시간을 1초 이하로 줄여, 성능을 2배 이상 향상시킬 수 있었습니다.
이 경험을 통해, 성능 문제에 직면했을 때 시스템을 세분화하고, 특정 부분에 집중하여 문제를 해결하는 방법에 대해 배울 수 있었습니다. 또한 성능 개선에 있어 지속적인 모니터링과 테스트의 중요성을 다시 한 번 인지하게 되었습니다.


[지원동기] - 회사명 써있으니까 수정할것
현재 다니고 있는 회사는 첫 회사로 하고 있는 일은 데이터분석 플랫폼 개발입니다
100명 가량의 사람들이 내가 만든 프로그램을 사용하고 있는것에는 만족감을 느끼고 있었습니다.
하지만 과연 좀 더 많은 사람들이 이용하는 플랫폼에도 내가 도움이 되지않을까 하는 생각도 매번 가지고 있었습니다
그렇게 생각만을 하고 있었던 저에게 가장 큰 동기부여가 되는 일이 있었습니다
aws 에서 하루동안 주최하는 워크샵에 참여하고 난 후 각 분야에서 프로라고 하는 사람들을 마주보게 되었을때 왜 나는 이 분야에서 만족감 만을 느끼고 프로가 되지 않으려고 하는가에 대해서 생각을 가지게 되었고 내가 현재 너무 안주하고 있는 삶을 사는게 아닌가하는 마음이 들었습니다
그래서 예전부터 스스로 프로의 영역이라는 [회사명]에 지원하는것이 나 스스로에게도 발전의 의미를 주는 시간이 되지않을까 하는 의미로 지원하게 되었습니다



---
layout: about
title: 오준혁
permalink: /about/
---

# About me
현재 Python과 Java 를 주력으로 만 2년차 백엔드 엔지니어로써 일하고 있습니다.

저는 개발자란 코딩을 하는 사람이 아닌 사용자가 원하는 데이터를 정확하고 신속하게 전달하는 방법을 탐구하고 개발해내는 사람이라 생각하고 있습니다

| github | [jheok](https://github.com/jheok), [jheok318](https://github.com/jheok318) |
|:-------|:---------------------------------------------------------------------------| 
| blog   | [jheok.github.io](https://jheok.github.io/about/)                          |

---
# Work Experience

## Mobigen (full-time employee)
> 웹 기반 빅데이터 분석 플랫폼 서비스

| period   | 21.01.01 ~ 현재 (2년 6개월) |
|:---------|:-----------------------|
| position | Python, Java 백엔드 엔지니어  |
| project  | 웹 백엔드 기반 데이터 분석 플랫폼 개발 |
{:.stretch-table}


### sql+dsl 기반 데이터(polars+pandas) 분석 플랫폼 개발 (21.11.01 ~ 현재, 1년 8개월, GS 인증 진행중)

- 개발언어 : Python(FastApi, SQLAlchemy)
- 개발 참여인원: 2명
- 쿼리 토큰화, 파싱 및 RSA 암호화를 통한 데이터 보안 강화
- Pandas 와 Polars 결합으로 데이터 분석 성능 및 처리 속도 대폭 개선
- python GIL 로 인한 성능저하의 문제를 멀티 프로세싱으로 인한 개선
- Yacc(parser)와 Lex(tokenizer)를 이용하여 높은 성능의 DSL 개발
- Jenkins 를 활용하여 CI/CD 프로세스 구현
- 최적화된 릴리스 버전 외부 업체에 배포 완료, [예시 사이트](https://bigtori.kalis.or.kr)

[담당 역할]
- 기획, 설계, 개발

[성과 및 배운점]
- 데이터베이스에 직접 연결하여 2~3초 가량의 쿼리 처리를 수행하던 기존 서비스가 존재하였으며, 현 서비스로 인해 같은 쿼리를 1초이내로 줄여 새로운 백엔드 서비스로 교체
- 쿼리와 DSL 기반의 접근 방식을 도입하여, 기존의 복잡한 쿼리를 DSL 을 활용해 단순하고 가독성 높은 형태로 변환. 이를 통해 개발 및 유지 보수 과정에서의 효율성을 크게 향상

[해당 프로젝트 진행중 가장 기억에 남는 문제 해결 경험]
해당 프로젝트는 가상화된 데이터를 SQL+DSL 명령어를 통해 db 에 직접 연결하여 db 단에서 처리된 데이터를 추가적으로 사용자가 원하는 데이터로 가공하여 물리데이터로 변환해주는 프로젝트입니다.
프로젝트를 진행하면서 동시에 여러 쿼리가 동시에 서비스에 도착하면 성능 저하가 발생하는 문제를 발견하였습니다.
이를 ngrinder를 이용하여 재현하였고, Log 를 분석하여 Python의 GIL 때문에 성능이 저하되는 것으로 판단하였습니다.
이 문제를 해결하기 위해, 원래 하나의 프로세스로 운영되던 서비스를 5개의 다른 프로세스로 분리하여 성능 향상을 이루었습니다.
1. 메인 서버 (Main Server): API 요청을 처리하고 전반적인 서비스 관리를 담당합니다.
2. PreFork 서버 (PreFork Server): subprocess를 미리 fork 하여 db와 connection 을 미리 맺어놓고 SQL 쿼리를 처리합니다.
3. Fork 서버 (Fork Server): SQL+DSL 쿼리가 들어올 때마다 subprocess를 fork하며, 쿼리 처리 작업의 부하를 줄였습니다.
4. 모니터링 서버 (Monitoring Server): 각 subprocess의 상태를 모니터링하며, 특히 zombie process에 대한 관리를 하였습니다.
5. 로그 서버 (Log Server): 각 프로세스에서 발생하는 로그를 관리하고 여러 프로세스의 로그를 하나의 파일형태로 저장합니다.
이러한 변경을 통해, 각 프로세스는 자신의 역할에 집중하고, 병목 현상을 최소화하여 성능을 향상을 하였습니다.
추가로, ngrinder를 이용하여 성능 테스트를 수행하고, 이를 기반으로 서비스의 성능 개선을 지속적으로 모니터링하였습니다. 
이 결과, 원래 2~3초가 걸리던 쿼리 처리 시간을 1초 이하로 줄여, 성능을 2배 이상 향상시킬 수 있었습니다.
이 경험을 통해, 성능 문제에 직면했을 때 시스템을 세분화하고, 특정 부분에 집중하여 문제를 해결하는 방법에 대해 배울 수 있었습니다.
또한 성능 개선에 있어 지속적인 모니터링과 테스트의 중요성을 다시 한 번 인지하게 되었습니다.

### dsl 기반 빅데이터(spark) 분석 플랫폼 (레거시) 유지보수 (21.01.01 ~ 현재, 2년 6개월)

- 개발언어 : Python(flask, SQLAlchemy)
- 개발 참여인원: 3명
- 고성능 빅데이터 분석 서비스를 위한 Spark 활용
- 쿼리 토큰화, 파싱 및 암호화(RSA) 처리 최적화
- Spark 의 고성능 분석을 위한 최적화된 conf 설정 구축
- 로그 분석 용이성을 위한 Spark job 로그 세팅
- Spark 클러스터 서버 업그레이드 (1G -> 10G, 소프트웨어적 부분 담당)
- yacc(parser), lex(tokenizer)를 이용한 효율적인 DSL 개발
- 고성능 Pyspark UDF 개발
- 대용량 데이터 처리를 위한 파티셔닝 최적화 (느린 쿼리를 1초 내로 개선)
- Jenkins 를 통한 CI/CD 진행
- 외부 업체에 성능 향상된 릴리즈 버전 배포 완료

[담당 역할]
- 설계, 개발

[성과 및 배운점]
- 레거시 프로그램의 구성을 수정하여 기존 성능 대비 2배 이상의 성능 및 속도 향상
- 레거시 프로그램에 대한 깊이 있는 이해와 그에 접근하는 방법을 습득
- 다양한 개발자들과 함께 작업하는 프로젝트에서 GitFlow 를 사용한 경험을 통해 팀 협업에 대한 충분한 지식을 습득
- Spark 와 같은 데이터 분석 도구에 대한 개념을 이해하고, 데이터 분석에 필요한 다양한 도구를 활용할 수 있는 역량을 습득
- 데이터베이스에서 사용되는 쿼리의 구조 및 파싱에 대한 이해를 바탕으로, 독립적으로 쿼리를 구현할 수 있는 능력 습득

[해당 프로젝트 진행중 가장 기억에 남는 문제 해결 경험]
해당 프로젝트는 가상화된 데이터를 DSL 명령어를 통해 spark 를 통해 사용자가 원하는 데이터로 가공하여 물리데이터로 변환해주는 프로젝트이다.
그중 사용자가 등록한 데이터에 일치하는 폴리곤을 추출하여 사용자 데이터와 가상화된 데이터의 polygon 을 join 하여 다시 전달하는 명령어에서 문제가 발생했다.
이유는 가상화된 데이터는 100GB 의 .csv 파일을 단순 분할하여 데이터를 보유하고 있었기 때문이다.   
당시 해당 DSL 명령어는 무거운 폴리곤 데이터를 가지고 있기 때문에 조회를 하는게 당연히 느린 DSL 명령어라고 생각하여 단순 몇건에 대한 데이터에 polygon 데이터를 join을 해주는 명령어로써 사용되고 있었다.
하지만 나는 spark 를 사용하고 있는데 데이터 분석이 느린지에 대해서 이해를 할 수 없었다.
이를 해결하기 위해 raw 기반의 .csv가 아닌 column 기반의 parquet을 채택했다. 그리고 spark 에서 파티셔닝 된 parquet 파일을 읽을수 있다는 걸 확인했고 100GB 이상의 파일을 파티셔닝하는 과정을 거쳤다
이를 통해 사용자가 다량의 데이터를 등록할지라도 1초내로 결과를 얻어낼수 있게 작업을 했다.
이 경험을 통해 내가 처한 이슈를 해결하기 위해선 단순히 코드를 개발하거나 수정하는것 뿐만이 아닌 다른 여러가지 방법들로 사용자의 불편함을 해결할 수 있게 도와줄수 있구나를 배웠다.


### CI/CD 강화 (23.04.01 ~ 23.05.31, 2개월)

- 개발 참여인원: 4명
- GitLab, Jenkins, ArgoCD를 활용한 고성능 CI/CD 구축 (Jenkins 통합화 및 GitLab 모듈화 기여)
- 효율적인 리소스 활용을 위한 통합 Jenkinsfile 구축 (모든 repo 에서 하나의 Jenkinsfile 로 통합)
- Jenkins, SonarQube, Slack 연동을 통한 일일 빌드 결과 및 성능 분석 보고 개선

[담당 역할]
- 개발

[성과 및 배운점]
- 기존의 단순한 단위 테스트와 빌드 과정을 확장하여, 엔드 투 엔드 테스트와 배포까지 포괄하는 통합적인 CI/CD 파이프라인을 구축
- 모든 repo 에서 일관된 CI/CD 프로세스를 구현하여, 개발자들이 초기 Dockerfile 작성 및 간단한 설정만으로 손쉽게 CI/CD를 진행할 수 있도록 개선
- 좋은 개발자가 되기 위해서는 코드 작성 능력 뿐만 아니라, Jenkins 와 같은 도구를 능숙하게 사용하는 것이 중요하다는 것을 깨달음

### 메타데이터 관리 서비스 개선 (23.01.01 ~ 23.03.31, 3개월)

- 개발언어 : Java(Spring, JPA)
- 개발 참여인원: 2명
- Spring Datasource 에서 Flyway 를 이용한 DB 형상관리로 마이그레이션 (DB 히스토리 구축)
- JPA 기반 성능 향상으로 데이터 로딩 개선 및 로드 시간 단축
- Jenkins 를 활용한 CI/CD 진행
- 성능 개선된 릴리즈 버전 외부 업체 배포 완료

[담당 역할]
- 기획, 설계, 개발

[성과 및 배운점]
- 메타데이터 조회 과정을 개선하여, 전체 데이터 분석 후 가져오는 방식에서 특정 메타데이터만 가져오는 방식을 채택하여 성능을 1초에서 0.01초 수준으로 향상
- 다른 개발자가 작성한 코드에 성능 향상을 중점으로 리뷰함으로써, 현재 보유한 지식을 활용하여 프로그램이 현 상황에 적합한지 판단하고, 필요한 부분에 집중할 수 있는 시간을 가짐

[해당 프로젝트 진행중 가장 기억에 남는 문제 해결 경험]
해당 프로젝트는 가상화 된 데이터의 모든 메타데이터를 조회/생성/삭제/업데이트 하는 프로젝트이다
당시 가상화 데이터를 불러오는 서비스에서 메타데이터 관리 서비스를 거쳐 필요한 데이터를 가져와 물리적인 데이터로 변경을 하는 로직이 존재했는데
물리적인 데이터로 변환하는 부분이 아닌 메타데이터 관리 서비스를 거치는 부분에서 오버헤드가 발생하는 것이 모니터링 됐었다.
당시 메타데이터를 RDB 로 관리하다보니 정규화 과정을 거쳐 테이블이 세분화 되어있었다.
그러다보니 데이터의 조회를 하는 부분에서 메타데이터의 id 하나에 관련된 모든 테이블을 즉시로딩하여 데이터를 가지고 오고있었고 확인해보니 초창기에 비해 메타데이터의 양이 너무 비대하게 적재되어있었다.
이를 해결하기 위해 모든 데이터를 fetch 하는데 있어 지연로딩으로 변경하였고 N+1 문제가 발생되지않도록 fetch join 을 사용하였고 각 엔티티마다 persistalbe 을 상속받아 필요하지 않은 부분에서 merge() 가 실행되어 select 쿼리가 추가적으로 호출되는것을 방지하였다. 
이로 인해 1초 대의 오버헤드가 0.01초 수준으로 내려갔다.
이 경험을 통해 spring을 spring 처럼 쓰는 방법을 배울수 있었다. 


### 파일 기반 데이터 분석 플랫폼 개발 (22.07.01 ~ 22.12.31, 6개월, 환경공단 납품 완료)

- 개발언어 : Java(Spring, JPA), Python(FastApi, SQLAlchemy)
- 개발 참여인원: 1명
- 탐색적 데이터 분석(EDA)을 통한 시각화 데이터 추출 및 성능 향상
- 자연어 처리(NLP)를 이용한 분석 데이터 추출과 최적화
- GEO 폴리곤 데이터 추출 및 처리 성능 개선
- 잡스케줄러 구조 적용으로 서비스 안정성 향상
- Jenkins를 활용한 CI 진행
- 성능 개선된 릴리즈 버전 외부 업체 배포 완료

[담당 역할]
- 기획, 설계, 개발

[성과 및 배운점]
- 다수의 사용자가 하나의 서비스에 접속해 서버 과부하가 발생하는 문제를 해결하기 위해 서버를 분할
  이를 통해 트래픽과 분석 데이터의 크기가 증가해도 대용량 데이터 분석이 가능
- 개발 과정에서 언어는 단순한 도구임을 깨달음
- 로드 밸런싱을 구현해 기존 하나의 서비스를 여러 개의 서비스로 분할함으로써, 동기화 문제 등 새로운 이슈가 발생할 수 있다는 것을 인식

[해당 프로젝트 진행중 가장 기억에 남는 문제 해결 경험]
프로젝트의 주된 내용은 파일기반 분산 코드 실행 및 잡스케줄링 개발이었습니다. 이를 위해 Agent Manager Service(AMS)와 Agent Executor Service(AES)라는 두 개의 서비스를 개발했습니다
AMS는 Java로 개발되었으며, AES와 AES에서 생성된 Task(subprocess)를 모니터링하고 관리하는 잡스케줄러의 마스터 역할을 하였습니다
AES는 Python으로 개발되었으며, AMS를 통해 API 요청을 받으면 Task(subprocess)를 생성하여 분석을 하는 워커 역할을 하였습니다
프로젝트를 진행하면서 가장 기억에 남았던 문제는 동시성 문제였습니다. 초기에는 AMS와 AES, 각각의 서비스마다 pod을 하나씩 구동하면서 개발을 진행하였습니다. 이 때에는 동시성 문제가 발생하지 않았습니다.
그러나 프로젝트가 진행되면서 pod 관리를 자동화하는 단계로 넘어갔을 때 문제가 발생하였습니다. Kubernetes의 자동 스케일링 기능에 의해 AES의 pod 개수가 증가함에 따라, 여러 개의 pod이 동일한 파일에 동시에 액세스하는 상황이 발생하였습니다.
이러한 동시성 문제를 해결하기 위해 락을 도입하였습니다. 락을 이용하면 여러 개의 프로세스가 동시에 같은 자원에 접근하려고 할 때, 한 번에 하나의 프로세스만 접근할 수 있도록 제어할 수 있었습니다.
이 방법을 통해 동시성 문제를 해결했었습니다
이 경험을 통해 분산 시스템에서 동시성 문제는 불가피하며, 이를 처리하는 방법을 알아야 한다는 것을 깨달았습니다. 특히, 락을 적용하면서 동시성 제어의 중요성을 체감했습니다.

### slow 쿼리 캐시서버 개발 (21.06.01~21.12.31, 6개월)

- 개발언어 : Python(FastApi, SQLAlchemy)
- 개발 참여인원: 1명
- 쿼리 토큰화, 파싱 및 RSA 암호화 처리를 통한 성능 최적화
- 분석 플랫폼 내의 느린 쿼리 파악 후 캐싱 적용으로 성능 개선
- 응답 시간이 기존 10초에서 1초로 크게 단축된 성능 향상
- Jenkins를 이용한 CI/CD 진행
- 뚜렷한 성능 향상 덕분에 메인 프로젝트로 승격 및 진행 (다른 프로젝트로 인해 승격 프로젝트는 미진행)

[담당 역할]
- 기획, 설계, 개발

[성과 및 배운점]
- DB에서 데이터를 가져오고 전달하는 데 수십 초 소요되던 무거운 데이터를 캐시 서버를 활용하여 1초 이내로 처리할 수 있게 됨
- 데이터 서빙 시 빠른 처리와 전달만이 해결책이 아니라, 중간에 매개체를 도입함으로써 복잡함 대신 때로는 간결함이 효과적인 해결 방법이 될 수 있다는 것을 깨달음

---
## Mobigen (intern)

| period   | 20.07.01 ~ 20.12.31 (6개월)                                 |                                 
|:---------|:----------------------------------------------------------|
| position | Python 백엔드 엔지니어                                           |
| project  | 웹 백엔드 기반 데이터 분석 플랫폼 개발                                    |
| tech     | Python & flask, pySpark, MariaDB, Postgresql, docker, k8s |
{:.stretch-table}

### 자체 DSL 및 spark 기반 데이터 분석프로그램 분석 & 개발 (20.07.01 ~ 20.12.31, 6개월)
- 핵심 프로그램의 코드 분석과 성능 중심의 QA 진행
- 프로그램 동작 이해 후, 성능 향상을 위한 추가 DSL 개발 및 테스트 코드 작성
- 인턴 기간 종료 1개월 전에 성능 최적화된 프로그램을 배포하고 릴리즈 완료

[담당 역할]
- 기획, 설계, 개발, QA

---
# Experienced Skill
> 현재까지 제가 경험하고 접했던 기술들 입니다, 학부 과정에서의 경험은 포함하지 않았습니다

| Skill           |                                                                                    |
|:----------------|:-----------------------------------------------------------------------------------|
| 프로그래밍 언어        | Java, Python, Groovy                                                               |
| 프레임워크           | FastAPI, Flask, Spring                                                             |
| 프로토콜            | Http, Https, Grpc                                                                  |
| ORM 프레임워크       | JPA, SQLAlchemy                                                                    |
| 데이터베이스          | MariaDB, PostgreSQL, Redis, Memcached, Tibero, Oracle, Altibase, Minio, HDFS, 자체DB |
| DB 형상관리 툴       | Flyway, alembic                                                                    |
| 분산처리 엔진         | Spark                                                                              |
| 데이터 분석 툴        | Pandas, Polars, Pyspark, Apache Sedona(geoSpark)                                   |
| 자연어 분석 툴        | TextRank, Mecab                                                                    |
| 파싱 툴            | Yacc, Lex                                                                          |
| CI/CD           | Jenkins, ArgoCD                                                                    |
| 테스트 툴           | doctest, junit5, unittest, ngrinder                                                |
| 컨테이너화 및 오케스트레이션 | Docker, Kubernetes (k8s)                                                           |
| 코드 분석 툴         | Sonarqube, flake8                                                                  |
| 에러 트래킹          | Sentry                                                                             |
| 버전 관리 및 협업 도구   | GitHub, GitLab, Jira, Swagger, Mattermost, Slack                                   |
| CI/CD 언어        | Declarative pipeline, Scripted pipeline                                            |
{:.stretch-table}

---
## 학력

### 한양대 (erica)

| period | 19.03 ~ 21.02 |
|:-------|:--------------|
| 전공     | 컴퓨터 공학과       |
| 성적     | 3.65 / 4.5    |
| 졸업상태   | 졸업 / 편입       |
{:.stretch-table}

---
## 자격증

### AWS Certified Developer Associate

| 취득일   | 23.01.20   |
|:------|:-----------|
| 제공사   | AWS        |
| 성적    | 724 / 1000 |
{:.stretch-table}

